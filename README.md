# Neural Network Robustness vs Interpretability
## Project Description
### Problem Motivation
Interpretable Machine Learning and Robust Machine Learning are two important fields of studies that aims to make Machine Learning models more reliable and trustworthy, especially in complex high-stake applications such as medicine, automatic vehicle, finance, law, etc. 

While our Machine Learning models have reached very high accuracy, it is still brittle under carefully-constructed adversarial attacks. With some carefully constructed noise added on top, an image that looks almost identical to us human eyes, will suddenly be classified as another picture by a Neural Network, even with very high confidence. This issue has boomed an era of study in Robust Machine Learning, including Robust Optimization(Link), Robust Regularizartion(Link),  Online Defense(Link), all aiming to improve the models' robustness under these adversarial examples. You can read more about this topic in our Midterm Seminar here().
![image](https://user-images.githubusercontent.com/59561588/146614009-dc0914f5-b52a-4e82-9067-8d0c89902ec1.png)

The Neural Network's vulnerability under adversarial attacks brings up another problem - in fact, we don't know what our models are doing when they are making decisions. We don't know why adversaries exists and what our models are learning and seeing when facing these adversaries. This brings up the other topic of our project - Interpretable Machine Learning. We would like to know what the models are doing for the sake of debugging, explaining to stakeholders, and taking accountabilities. Moreover, we just want to make sure our model is reliable, right?

We look at these two intrinsincally intertwined sub-fields of machine learning, and we want to answer the following questions: if robust models are "immune" to the noise in the pictures, then are they learning the "semantically meaningful" features that we see as human eyes? If so, are robust model more interpretable than naturally trained models?
### Approach and Experiment Design
#### Interpreting Neural Network
#### Robust Models
#### Experiment Design
## Repo Description
## Running the demo
## Results
